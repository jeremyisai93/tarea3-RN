{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.datasets import imdb\n",
    "np.random.seed(3)\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(seed=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review length: \n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSSVlAEhSSf1/peDTyD9teN8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f63a0565710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X = np.concatenate((X_train, X_test), axis=0)\n",
    "y = np.concatenate((y_train, y_test), axis=0)\n",
    "from matplotlib import pyplot\n",
    "print(\"Review length: \")\n",
    "result = map(len, X)\n",
    "pyplot.boxplot(result)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=3000, seed=15)\n",
    "from keras.preprocessing import sequence\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=500)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers.embeddings import Embedding\n",
    "\n",
    "\n",
    "def generate_model(top_words, embedding_length, n_lstm_units=100, dropout=None):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(top_words, embedding_length, input_length=500))\n",
    "    if dropout is not None:\n",
    "        model.add(Dropout(dropout))\n",
    "    model.add(LSTM(n_lstm_units))\n",
    "    if dropout is not None:\n",
    "        model.add(Dropout(dropout))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 500, 32)           96000     \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 100)               53200     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 149,301\n",
      "Trainable params: 149,301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "from keras.models import load_model\n",
    "model = generate_model(top_words=3000, embedding_length=32, n_lstm_units=100)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/3\n",
      "25000/25000 [==============================] - 746s - loss: 0.4933 - acc: 0.7567 - val_loss: 0.3580 - val_acc: 0.8494\n",
      "Epoch 2/3\n",
      "25000/25000 [==============================] - 622s - loss: 0.3177 - acc: 0.8706 - val_loss: 0.3992 - val_acc: 0.8584\n",
      "Epoch 3/3\n",
      "25000/25000 [==============================] - 621s - loss: 0.3141 - acc: 0.8694 - val_loss: 0.3167 - val_acc: 0.8691\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=3, batch_size=64)\n",
    "model.save('lstm100_embedding32.h5')\n",
    "model.save('lstm100_topWord3000.h5')\n",
    "#scores = model.evaluate(X_test, y_test, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.316668782351\n",
      "Test accuracy: 0.86912\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss: {0}'.format(scores[0]))\n",
    "print('Test accuracy: {0}'.format(scores[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/3\n",
      "25000/25000 [==============================] - 1000s - loss: 0.4907 - acc: 0.7606 - val_loss: 0.3796 - val_acc: 0.8384\n",
      "Epoch 2/3\n",
      "25000/25000 [==============================] - 752s - loss: 0.3234 - acc: 0.8675 - val_loss: 0.2993 - val_acc: 0.8736\n",
      "Epoch 3/3\n",
      "25000/25000 [==============================] - 809s - loss: 0.2725 - acc: 0.8928 - val_loss: 0.3131 - val_acc: 0.8739\n",
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/3\n",
      "25000/25000 [==============================] - 2178s - loss: 0.4793 - acc: 0.7638 - val_loss: 0.4006 - val_acc: 0.8198\n",
      "Epoch 2/3\n",
      "22400/25000 [=========================>....] - ETA: 326s - loss: 0.3527 - acc: 0.8529"
     ]
    }
   ],
   "source": [
    "embedding_lengths = [128,512,1024]#falta 8\n",
    "\n",
    "for length in embedding_lengths:\n",
    "    model = generate_model(top_words=3000, embedding_length=length, n_lstm_units=100)\n",
    "    # fitting the model\n",
    "    hist = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=3, batch_size=64)\n",
    "    # saving the model\n",
    "    model.save('lstm100_embedding'+str(length)+'.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "top_words = [1000,2000,4000,5000]\n",
    "\n",
    "for length in top_words:\n",
    "    model = generate_model(top_words=length, embedding_length=32, n_lstm_units=100)\n",
    "    # fitting the model\n",
    "    hist = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=3, batch_size=64)\n",
    "    # saving the model\n",
    "    model.save('lstm100_topWord'+str(length)+'.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = generate_model(top_words=3000, embedding_length=32, n_lstm_units=100, dropout=0.2 )\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hist = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=3, batch_size=64)\n",
    "model.save('lstm100_dropout02.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
